{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SigNet_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswit3/SigNet_Pytorch/blob/master/SigNet_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "esGrw0waQlwP",
        "colab": {}
      },
      "source": [
        "# Import all the necessary Library \n",
        "import torchvision\n",
        "import torch.utils.data as utils\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils\n",
        "import numpy as np\n",
        "import time\n",
        "import copy\n",
        "from torch.optim import lr_scheduler\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import PIL.ImageOps    \n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VC5JhgpcPmP6",
        "colab": {}
      },
      "source": [
        "class SiameseNetworkDataset():\n",
        "    \n",
        "    def __init__(self,training_csv=None,transform=None):\n",
        "        self.training_df= training_csv\n",
        "        self.training_df.columns =[\"image1\",\"image2\",\"label\"]\n",
        "        self.transform = transform\n",
        "        self.training_dir = \"/home/dell/SigNet_Pytorch/\"\n",
        "\n",
        "    def __getitem__(self,index):    \n",
        "        # getting the image path\n",
        "        image1_path=self.training_df.iat[index,0].replace(\"./\", self.training_dir)\n",
        "        image2_path=self.training_df.iat[index,1].replace(\"./\", self.training_dir)\n",
        "                \n",
        "        # Loading the image\n",
        "        img0 = Image.open(image1_path)\n",
        "        img1 = Image.open(image2_path)\n",
        "        img0 = img0.convert(\"L\")\n",
        "        img1 = img1.convert(\"L\")\n",
        "        \n",
        "        # Apply image transformations\n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "        \n",
        "        return img0, img1 , torch.from_numpy(np.array([int(self.training_df.iat[index,2])],dtype=np.float32))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.training_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvNP-W5J0upC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_csv =pd.read_csv(\"chineese_train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6ECtw270upT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_csv = pd.read_csv(\"chineese_test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfCJ1CrL0upm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "val_csv, test_csv = train_test_split(val_csv, test_size=0.5, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttBPM94H0uqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_csv = training_csv.head(100)\n",
        "val_csv = val_csv.head(10)\n",
        "test_csv = val_csv.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ws1NipMUQaI3",
        "colab": {}
      },
      "source": [
        "# Load the the dataset from raw image folders\n",
        "train_siamese_dataset = SiameseNetworkDataset(training_csv,\n",
        "                                        transform=transforms.Compose([transforms.Resize((105,105)),\n",
        "                                                                      transforms.ToTensor()\n",
        "                                                                      ])\n",
        "                                       )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9V7dRsu0uqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the the dataset from raw image folders\n",
        "val_siamese_dataset = SiameseNetworkDataset(val_csv,\n",
        "                                        transform=transforms.Compose([transforms.Resize((105,105)),\n",
        "                                                                      transforms.ToTensor()\n",
        "                                                                      ])\n",
        "                                       )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-aOPJTe0uqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the the dataset from raw image folders\n",
        "test_siamese_dataset = SiameseNetworkDataset(test_csv,\n",
        "                                        transform=transforms.Compose([transforms.Resize((105,105)),\n",
        "                                                                      transforms.ToTensor()\n",
        "                                                                      ])\n",
        "                                       )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5xhlmF-nj6_v"
      },
      "source": [
        "## Siamese Network Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MjkBkyTomlU6",
        "colab": {}
      },
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        \n",
        "        # Setting up the Sequential of CNN Layers\n",
        "        self.cnn1 = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(1, 96, kernel_size=11,stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            \n",
        "            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "\n",
        "            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "\n",
        "        )\n",
        "        \n",
        "        # Defining the fully connected layers\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(30976, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.5),\n",
        "            \n",
        "            nn.Linear(1024, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(128,2))\n",
        "        \n",
        "  \n",
        "  \n",
        "    def forward_once(self, x):\n",
        "        # Forward pass \n",
        "        output = self.cnn1(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # forward pass of input 1\n",
        "        output1 = self.forward_once(input1)\n",
        "        # forward pass of input 2\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2xaKRzCV-vBD"
      },
      "source": [
        "### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nBjCIlhWk2MT",
        "colab": {}
      },
      "source": [
        "class ContrastiveLoss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Contrastive loss function.\n",
        "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
        "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "\n",
        "\n",
        "        return loss_contrastive, euclidean_distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UyGA_GUt-0xp"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgUkneFI0usj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config():\n",
        "    train_batch_size = 1\n",
        "    val_batch_size = 1\n",
        "    test_batch_size = 1\n",
        "    train_number_epochs = 5\n",
        "    patience = 3\n",
        "    checkpoint_dir =\"./checkpoints/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xO9uIznkXiB0",
        "colab": {}
      },
      "source": [
        "# Load the dataset as pytorch tensors using dataloader\n",
        "train_dataloader = DataLoader(train_siamese_dataset,\n",
        "                        shuffle=True,\n",
        "                        num_workers=8,\n",
        "                        batch_size=Config.train_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnAMkThw0utL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataloader = DataLoader(val_siamese_dataset,\n",
        "                        shuffle=True,\n",
        "                        num_workers=8,\n",
        "                        batch_size=Config.val_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih294BlB0utW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataloader = DataLoader(test_siamese_dataset,\n",
        "                        shuffle=True,\n",
        "                        num_workers=8,\n",
        "                        batch_size=Config.test_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tspmR_2bd824",
        "colab": {}
      },
      "source": [
        "# Check whether you have GPU is loaded or not\n",
        "if torch.cuda.is_available():\n",
        "    print('Yes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dPnzoTXfE5cX",
        "colab": {}
      },
      "source": [
        "# Declare Siamese Network\n",
        "net = SiameseNetwork()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    net = nn.DataParallel(net)\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "# Decalre Loss Function\n",
        "criterion = ContrastiveLoss()\n",
        "# Declare Optimizer\n",
        "optimizer = optim.RMSprop(net.parameters(), lr=1e-4, alpha=0.99, eps=1e-8, weight_decay=0.0005, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGrggHt80uuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_ckp(state, is_best, checkpoint_dir):\n",
        "    f_path = checkpoint_dir+'checkpoint.pt'\n",
        "    torch.save(state, f_path)\n",
        "    if is_best:\n",
        "        best_fpath = checkpoint_dir+'best_model.pt'\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScD3eVvR0uuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    return model, optimizer, checkpoint['epoch']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx92pPVG0uua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model, optimizer, epoch, checkpoint_dir):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, optimizer, epoch, checkpoint_dir)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, optimizer, epoch, checkpoint_dir)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model, optimizer, epoch, checkpoint_dir):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        \n",
        "        is_best = True\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "        save_ckp(checkpoint, is_best, checkpoint_dir)\n",
        "        \n",
        "        torch.save(model, self.path) # model.state_dict()\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6aUJOhkrFfu9",
        "colab": {}
      },
      "source": [
        "def train(net, optimizer, epoch_start):     \n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    avg_train_losses = []\n",
        "    avg_valid_losses = [] \n",
        "    \n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=Config.patience, verbose=True)\n",
        "    \n",
        "    for epoch in range(epoch_start,Config.train_number_epochs):\n",
        "        for batch_idx, (img0, img1, label) in enumerate(train_dataloader):\n",
        "            img0, img1 , label = img0.to(device), img1.to(device) , label.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output1,output2 = net(img0,img1)\n",
        "            loss_contrastive, _ = criterion(output1,output2,label)\n",
        "            \n",
        "            loss_contrastive.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_losses.append(loss_contrastive.item())            \n",
        "                        \n",
        "            if batch_idx % 10 == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(img0), len(train_dataloader.dataset),\n",
        "                    100. * batch_idx / len(train_dataloader), loss_contrastive.item()))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in val_dataloader:\n",
        "                img0, img1 , label = data\n",
        "                img0, img1 , label = img0.to(device), img1.to(device) , label.to(device)\n",
        "\n",
        "                net.eval()\n",
        "                \n",
        "                output1,output2 = net(img0,img1)\n",
        "                validation_loss, _ = criterion(output1,output2,label)\n",
        "                \n",
        "                valid_losses.append(validation_loss.item())\n",
        "\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)     \n",
        "                     \n",
        "        print(f'Average Train_loss: {train_loss:.5f} ' + f'Average Validation_loss: {valid_loss:.5f}')\n",
        "        \n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "\n",
        "        early_stopping(valid_loss, net, optimizer, epoch, Config.checkpoint_dir)\n",
        "        \n",
        "        print(\"\\n\")\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "    checkpoint = {\n",
        "        'epoch': epoch + 1,\n",
        "        'state_dict': net.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()\n",
        "    }\n",
        "\n",
        "    is_best = False\n",
        "    save_ckp(checkpoint, is_best, Config.checkpoint_dir)\n",
        "    print(\"Model Saved Successfully\")\n",
        "    return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj1FMyiF0uu3",
        "colab_type": "code",
        "colab": {},
        "outputId": "258319e3-2a9f-435e-bf17-087259a88e51"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "Resume_training = True\n",
        "# Resume_training = False\n",
        "\n",
        "if Resume_training:\n",
        "    best_fpath =  Config.checkpoint_dir+'best_model.pt'\n",
        "    net, optimizer, start_epoch = load_ckp(best_fpath, net, optimizer)\n",
        "    print(start_epoch)\n",
        "    model = train(net, optimizer, start_epoch)\n",
        "else:\n",
        "    # Train the model\n",
        "    model = train(net, optimizer, 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "Train Epoch: 3 [0/10 (0%)]\tLoss: 3.667839\n",
            "Average Train_loss: 1.19972 Average Validation_loss: 0.00569\n",
            "Validation loss decreased (inf --> 0.005693).  Saving model ...\n",
            "\n",
            "\n",
            "Train Epoch: 4 [0/10 (0%)]\tLoss: 0.001533\n",
            "Average Train_loss: 1.04869 Average Validation_loss: 0.16915\n",
            "EarlyStopping counter: 1 out of 3\n",
            "\n",
            "\n",
            "Model Saved Successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sqP-osT0uu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy_roc(predictions, labels):\n",
        "    '''Compute ROC accuracy with a range of thresholds on distances.\n",
        "    '''\n",
        "    dmax = np.max(predictions)\n",
        "    dmin = np.min(predictions)\n",
        "    nsame = np.sum(labels == 1)\n",
        "    ndiff = np.sum(labels == 0)\n",
        "   \n",
        "    step = 0.01\n",
        "    max_acc = 0\n",
        "    best_thresh = -1\n",
        "   \n",
        "    for d in np.arange(dmin, dmax+step, step):\n",
        "        idx1 = predictions.ravel() <= d\n",
        "        idx2 = predictions.ravel() > d\n",
        "       \n",
        "        tpr = float(np.sum(labels[idx1] == 1)) / nsame       \n",
        "        tnr = float(np.sum(labels[idx2] == 0)) / ndiff\n",
        "        acc = 0.5 * (tpr + tnr)       \n",
        "#       print ('ROC', acc, tpr, tnr)\n",
        "       \n",
        "        if (acc > max_acc):\n",
        "            max_acc, best_thresh = acc, d\n",
        "           \n",
        "    return max_acc, best_thresh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PzR4HPv0uvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize lists to monitor test loss and accuracy\n",
        "test_loss = 0.0\n",
        "accuracy=0\n",
        "counter=0\n",
        "correct=0\n",
        "\n",
        "pred, tr_y = [], []\n",
        "\n",
        "model.eval() # prep model for evaluation\n",
        "\n",
        "for data in test_dataloader:\n",
        "    img0, img1 , label = data\n",
        "    img0, img1 , label = img0.to(device), img1.to(device) , label.to(device)\n",
        "\n",
        "    output1,output2 = model(img0,img1)\n",
        "    loss, distance = criterion(output1,output2,label)\n",
        "    \n",
        "    test_loss += loss.item()    \n",
        "\n",
        "    res=torch.abs(output1.to(device) - output2.to(device))\n",
        "    label=label[0].tolist()\n",
        "    label=int(label[0])\n",
        "    \n",
        "    tr_y.append(label)\n",
        "    pred.append(distance.item())\n",
        "    \n",
        "    result = torch.max(res,1)[1].item()\n",
        "    \n",
        "    if label == result:\n",
        "        correct=correct+1\n",
        "    counter=counter+1\n",
        "\n",
        "# calculate and print avg test loss\n",
        "test_loss = test_loss/len(test_dataloader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "accuracy=(correct/len(test_dataloader))*100\n",
        "print(\"Accuracy:{}%\".format(accuracy))\n",
        "tr_acc, threshold = compute_accuracy_roc(np.array(pred), np.array(tr_y))\n",
        "print(\"Accuracy =\", tr_acc, \"Threshold =\", threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slNjiyh_0uvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}